{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of transit windows using new routines.\n",
    "- This set of routines is trying to improve on the original version of the transit planner. Right now it is in state of development, with the core features being written. Several bugs are likely still present, though they should be more target-specific. Please report any bugs on the GitHub page.\n",
    "\n",
    "## Main changes are:\n",
    "- Code is written in way that it can be called as a library, so we no longer need to re-run/ save the target_list values from `target_selection.py`.\n",
    "- Currently, only NASA exoplanet archive is considered. The table is loaded automatically through TAP service, which is then stored locally as pickle file.\n",
    "- Transit windows now have an optimal observation window information, which gives sufficient baseline for both transmission spectroscopy and Rossiter-McLaughlin effect observation.\n",
    "- Transit windows are ranked based on quality. This is the main reason (together with p2 API system) this code was done.\n",
    "- For transmission spectroscopy, a simulated dataset can be done (for now only for Na doublet line, though it will be expanded upon).\n",
    "- Code should be properly documented, and generally easier to expand on.\n",
    "\n",
    "## Known bugs:\n",
    "- The observation window selection fails in some low quality transits (very visibly). \n",
    "    - This issue should be fixed\n",
    "- The quality of windows violating Moon constraint should be worse.\n",
    "\n",
    "\n",
    "## To be done:\n",
    "- Optimalization:\n",
    "    - The code currently runs slightly slower than the old planner. Furthermore, at high number of targets it might break due to memory issues.\n",
    "        - The first issue is not overly significant on my laptop (this can still be run relativelly fast). Please tell me if you need it to be faster. The reasoning is that currently most arrays are calculated even for very bad transit windows (e.g., non-visible targets), so a preselection would solve this issue. There is also an additional \"overhead\" due to loading of NASA archive through API on the first run or when updating the table.\n",
    "        - It should also be possible to do multiprocessing here.\n",
    "        - Second issue is likely solved. I am keeping this info here for logkeeping.\n",
    "- Re-adding lower priority features:\n",
    "    - Parameters like SNR from RMR for transit, TSM etc.\n",
    "    - Possibly: Other tables of exoplanets. However, many of these are not as precise as NASA archive is.\n",
    "- Simulation of RM contamination on to the transmission spectrum.\n",
    "- Adding custom ephemeris:\n",
    "    - Currently, there are two ways to add custom ephemeris.\n",
    "        1. Through `Exoplanets.add_custom_ephemeris()` function to load a single ephemeris set.\n",
    "        2. Through `Exoplanets.load_csv_ephemeris()` function to load csv file.\n",
    "    - More options will be considered based on user-cases.\n",
    "- Reimplement the NASA_exo.py using the rats.parameters CompositeTable class (personal pipeline, will be added separately).\n",
    "    - This shouldn't change the usage of the library, but it will provide additional functionalities (plots)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example on the TOI-132b.\n",
    "1. First, lets import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/media/chamaeleontis/Observatory_main/Code/observations_transits/OT/OT')\n",
    "from NASA_exo import NASA_Exoplanets_archive, logger, load_csv_ephemeris\n",
    "from utilities import logger_default\n",
    "import calculate_transit_windows as ctw\n",
    "import astropy.time as astime\n",
    "import astropy.units as u\n",
    "# import simulate_transmission_spectrum as sts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the NASA exoplanet archive\n",
    "- By using the `force_reload` keyword, you force the TAP service to be reloaded. Regardless of this keyword, on first time it will always be loaded anyway, since no saved data will be found.\n",
    "- `use_PS` keyword allows to disable the `Planetary Systems` table, and only uses the composite table. This is generally not prefered, and is set to `False` by default. If set to true, the table is still loaded to fix several parameter issues in composite table (e.g., parameteres without errorbars, which would later break the code), but afterwards the table is lost. \n",
    "- `full_PS` keyword forces usage of the full `Planetary Systems` table from NASA archive, which is *huge*. It will take easily an hour to load, so by default it is disabled. If disabled, only the Ephemeris related parameters are loaded ($P$, $T_{14}$ and $T_{c}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exoplanets = NASA_Exoplanets_archive(\n",
    "    force_reload = True,\n",
    "    # use_PS = False,\n",
    "    full_PS = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Filter out target sample based on criteria:\n",
    "- I tried to make this part as close as to `target_selection.py` filtering. The main difference is the keywords are not changed to the more natural ones, but used from the NASA exoplanet archive table [link_to_definitions_here](https://exoplanetarchive.ipac.caltech.edu/docs/API_PS_columns.html).\n",
    "- The pandas table is saved in `Exoplanets` class as `nasa_table_composite` (`Planetary systems Composite` table) and `nasa_table_all` (`Planetary systems`). Therefore all filters are done on `Exoplanets.nasa_table_composite` and `Exoplanets.nasa_table_all`, both of which are pandas DataFrames.\n",
    "- For the filters to be used, use: `Exoplanets.filter_table_composite(condition)` or `Exoplanets.filter_table_all(condition)`. This returns a DataFrame that can be checked for output, but otherwise is unused. The used table is stored in `Exoplanets.filtered_table_composite` and `Exoplanet.filtered_table_all` keys. The filter is automatically binded between the tables, so filters for composite table are applied to full table and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Condition for filtering table\n",
    "condition = (Exoplanets.nasa_table_composite['pl_name'].isin(\n",
    "    ['TOI-132 b',]\n",
    "    ))\n",
    "# The filtered_table argument is not used later, but is returned for checking the outputs.\n",
    "filtered_table = Exoplanets.filter_table_composite(condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Decide on period during which to calculate the transit windows:\n",
    "- A simple function is defined for the ESO semester numbering, using the `ctw.get_dates_for_ESO_semester()` function.\n",
    "- The dates are saved in `astime.Time` object, which is astropy Time package allowing for conversion between dates. This is used in the code, so simple 'yyyymmdd' format won't work. However, if necessary a convenient function can be written as well. The commented line shows how you can custom define a specific date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Get current large program dates\n",
    "P113 = ctw.get_dates_for_ESO_semester(P_number= 113,\n",
    "                                        large_program=False)\n",
    "\n",
    "# P112_115 = astime.Time(['2023-12-16 12:00:00.000', '2024-04-01 12:00:00.000'],scale = 'utc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calculate transit windows:\n",
    "- This step calculates *all* transit windows location, regardless of their validity and location.\n",
    "- `database` is the Exoplanets table from which to look for parameters of planets that have been previously selected.\n",
    "- The `semester_date` is the time where we look for the windows.\n",
    "- `save_directory` creates main folder where to save (eventually) the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transit_windows = ctw.Transit_windows(\n",
    "    database = Exoplanets,\n",
    "    semester_date = P113,\n",
    "    save_directory = '/media/chamaeleontis/Observatory_main/ESO_scheduling/CTW_ATREIDES_P113'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Plot transit windows:\n",
    "- Plots transit windows, provided location.\n",
    "- `Location` must be defined in the `observatories.py` `Observatories` Enum. If your observatory is not defined, you can define it there. `Astropy` will very likely have it in a list, but otherwise it can be also defined manually. Check the documentation for the class on how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transit_windows.plot_transit_windows(Location = 'Paranal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional:\n",
    "- Simulation of transmission spectrum for given transit.\n",
    "    - This takes as input the stellar and planetary parameters.\n",
    "    - It creates a stellar synthetic spectrum using PHOENIX\n",
    "    - Creates an estimated dataset (currently only ESPRESSO) assuming 900s of exposures.\n",
    "    - Injects a sodium doublet signal based on empirical trend in the planet spectra\n",
    "    - Calculates the synthetic transmission spectrum\n",
    "    - To do: \n",
    "        - Fit the signal and compare it with the injected signal\n",
    "        - Check the strength of the signal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
